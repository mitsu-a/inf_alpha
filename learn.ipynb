{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-d2Cal6QM2B"
      },
      "source": [
        "学習用コード．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUeJbQKcCnIs",
        "outputId": "e106bdb6-0876-4de2-f9d7-d34193c15223"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "rundir = \"/content/drive/MyDrive/infalpha/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Qg99WNRntBZN"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import sklearn as sk\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pylab as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import random\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Dropout, Activation, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from datetime import date, timedelta\n",
        "from tensorflow.python.keras.models import load_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIMca50uDLiv",
        "outputId": "905519da-179a-485f-e2ef-6a9a5d48b76e"
      },
      "outputs": [],
      "source": [
        "#1461日分のデータがある\n",
        "#データ数を減らした状態で扱う．(1458 - dec_cnt) 個．\n",
        "dec_cnt = 1420 #GitHubにアップロードしているデータは50件程度しかないため．実際の学習の際はdec_cntを1200程度にしていた．\n",
        "start_date = 0 ##############学習時はこの値を適当に変更##############\n",
        "#前3日分+当日の降水量を用いて予測→4日分でひとまとまりのイメージ\n",
        "#1458個のデータにできる\n",
        "\n",
        "#快晴などの天気のデータを「晴れ」「雨」「曇り」「その他」に分類．雪などは雨．\n",
        "def get_val(v):\n",
        "    #快晴，晴れ\n",
        "    if v==1 or v==2:\n",
        "        return 0\n",
        "    #雨，みぞれ，雪，あられ，ひょう，雷，霧，霧雨\n",
        "    if 8<=v and v<=15:\n",
        "        return 1\n",
        "    #曇り，薄曇り\n",
        "    if v==3 or v==4:\n",
        "        return 2\n",
        "    return 3\n",
        "\n",
        "\n",
        "x = [[] for i in range(start_date, 1458 - dec_cnt + start_date)]\n",
        "y = [0 for i in range(start_date, 1458 - dec_cnt + start_date)]\n",
        "for toshi in ['tokyo', 'nagoya', 'osaka', 'nigata', 'sendai', 'kagoshima']:\n",
        "    with open(rundir + toshi + '2.csv', 'r') as f:\n",
        "        read = csv.reader(f)\n",
        "        l = [row for row in read]\n",
        "        for i in range(1 + start_date,1459 - dec_cnt + start_date):\n",
        "            #i, ..., i+2 行目をxに用いる\n",
        "            for j in range(3):\n",
        "                x[i-1-start_date] += l[i+j]\n",
        "            #i+3行目の天気のデータがyに．\n",
        "            #晴れ系統，雨雪系統，曇り系統，その他　に分類\n",
        "            if toshi == 'tokyo':\n",
        "                y[i-1-start_date] = get_val(int(l[i+3][4]))\n",
        "for toshi in ['choshi', 'kumagaya', 'koufu', 'yokohama']:\n",
        "    with open(rundir + toshi + '2.csv', 'r') as f:\n",
        "        read = csv.reader(f)\n",
        "        l = [row for row in read]\n",
        "        #l[i][5]を全て消す\n",
        "        for i in range(len(l)):\n",
        "            l[i].pop(5)\n",
        "        for i in range(1 + start_date,1459 - dec_cnt + start_date):\n",
        "            #i, ..., i+2 行目をxに用いる\n",
        "            for j in range(3):\n",
        "                x[i-1-start_date] += l[i+j]\n",
        "for i in range(len(x)):\n",
        "    for j in range(len(x[0])):\n",
        "        if x[i][j] == '':\n",
        "            x[i][j] = -100. # 欠損データは-100を割り当てておく．\n",
        "        else:\n",
        "            x[i][j] = np.float32(x[i][j])\n",
        "    y[i] = int(y[i])\n",
        "\n",
        "for i in range(len(x)):\n",
        "    x[i] = np.array(x[i])\n",
        "\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "y = to_categorical(y) #ワンホットベクトルに"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sOsv5RQGHjfJ"
      },
      "outputs": [],
      "source": [
        "#訓練データの準備\n",
        "\n",
        "def get_imgs_array(name, size):\n",
        "    with open(rundir + name) as f:\n",
        "        return (np.array(list(map(int, f.readlines()[0].split())))).reshape(size)\n",
        "\n",
        "#画像たちをどうにかする場所\n",
        "#chart : 450 * 600 で RGB\n",
        "#rader : 520 * 692  で RGB\n",
        "#satellite : 520 * 692 で RGB\n",
        "\n",
        "#1/3からスタートなので注意．\n",
        "#1458個データがある\n",
        "ALL_DATA = [i for i in range(start_date, 1458 - dec_cnt + start_date)]\n",
        "TRAIN_DATA, TEST_DATA = train_test_split(ALL_DATA, test_size=0.05, random_state=42)\n",
        "\n",
        "#テストデータは使う時にやる．RAMを確保したいのでとりあえず空に．\n",
        "model = []\n",
        "x_test = []\n",
        "y_test = []\n",
        "c_18_test = []\n",
        "r_18_test = []\n",
        "\n",
        "#ここから訓練データ\n",
        "x_train = []\n",
        "y_train = []\n",
        "c_18_train = []\n",
        "r_18_train = []\n",
        "\n",
        "for i in TRAIN_DATA:\n",
        "    y_train.append(y[i-start_date])\n",
        "    x_train.append(x[i-start_date])\n",
        "    c_18_train.append(get_imgs_array('chart/' + format(i,'#4') + '-18.txt', (450, 600, 3))/255)\n",
        "    r_18_train.append(get_imgs_array('rader/' + format(i,'#4') + '-18.txt', (520, 692, 3))/255)\n",
        "x_train = np.array(x_train)\n",
        "c_18_train = np.array(c_18_train)\n",
        "r_18_train = np.array(r_18_train)\n",
        "y_train = np.array(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QkUMPSMo8f3T",
        "outputId": "21875a4f-8dcf-4db3-c792-f9dc17115b8d"
      },
      "outputs": [],
      "source": [
        "#0から学習する場合 - 1/2\n",
        "\n",
        "input_dim = 3 * (10 * 7 - 4) #10都市，3日分のデータを用いる．雲量を使わない箇所が4つあるので注意\n",
        "output_dim = 4 #晴れ，雨，曇り，その他　に分類．\n",
        "\n",
        "#画像関連\n",
        "#chart : 600 * 450 で RGB\n",
        "#rader : 692  * 520 で RGB\n",
        "#satellite : 692  * 520 で RGB\n",
        "\n",
        "inputs = Input(shape=(input_dim,), name=\"Input\")\n",
        "middle1 = Dense(30, activation=\"linear\", name=\"1st\")(inputs)\n",
        "normal_1 = BatchNormalization()(middle1)\n",
        "act_1 = Activation('relu')(normal_1)\n",
        "middle2 = Dense(30, activation=\"linear\", name=\"2nd\")(act_1)\n",
        "normal_2 = BatchNormalization()(middle2)\n",
        "act_2 = Activation('relu')(normal_2)\n",
        "\n",
        "#画像の方の入力口\n",
        "inputs_c18 = Input(shape=(450, 600, 3), name=\"Input_c18\")\n",
        "conv_c18 = Conv2D(2,(9, 9),activation=\"linear\", name=\"conv_c18\")(inputs_c18)\n",
        "normalize_c = BatchNormalization()(conv_c18)\n",
        "act_c = Activation('relu')(normalize_c)\n",
        "maxpooling_c = MaxPooling2D(pool_size=(2, 2), name=\"c18_pooling\")(act_c)\n",
        "conv_c18_2 = Conv2D(2,(9, 9),activation=\"linear\", name=\"conv_c18_2\")(maxpooling_c)\n",
        "normalize_c_2 = BatchNormalization()(conv_c18_2)\n",
        "act_c_2 = Activation('relu')(normalize_c_2)\n",
        "maxpooling_c_2 = MaxPooling2D(pool_size=(2, 2), name=\"c18_pooling_2\")(act_c_2)\n",
        "flat_c18 = Flatten(name=\"flat_c18\")(maxpooling_c_2)\n",
        "last_c = Dense(11, activation='relu', name='last_c')(flat_c18)\n",
        "\n",
        "\n",
        "inputs_r18 = Input(shape=(520, 692, 3), name=\"Input_r18\")\n",
        "conv_r18 = Conv2D(2,(9,9),activation=\"linear\", name=\"conv_r18\")(inputs_r18)\n",
        "normalize_r = BatchNormalization()(conv_r18)\n",
        "act_r = Activation('relu')(normalize_r)\n",
        "maxpooling_r = MaxPooling2D(pool_size=(2, 2), name=\"r18_pooling\")(act_r)\n",
        "conv_r18_2 = Conv2D(2,(9,9),activation=\"linear\", name=\"conv_r18_2\")(maxpooling_r)\n",
        "normalize_r_2 = BatchNormalization()(conv_r18_2)\n",
        "act_r_2 = Activation('relu')(normalize_r_2)\n",
        "maxpooling_r_2 = MaxPooling2D(pool_size=(2, 2), name=\"r18_pooling_2\")(act_r_2)\n",
        "flat_r18 = Flatten(name=\"flat_r18\")(maxpooling_r_2)\n",
        "last_r = Dense(11, activation='relu', name='last_r')(flat_r18)\n",
        "\n",
        "\n",
        "combined = tf.keras.layers.concatenate([act_2, last_c, last_r])\n",
        "outputs = Dense(output_dim, activation='softmax', name=\"3rd\")(combined)\n",
        "\n",
        "\n",
        "model = keras.Model(inputs=[inputs, inputs_c18, inputs_r18], outputs=outputs, name=\"weather_forecast\")\n",
        "model.summary()\n",
        "keras.utils.vis_utils.plot_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "gziPYicGWFrL"
      },
      "outputs": [],
      "source": [
        "#0から学習する場合 - 2/2\n",
        "model.compile(\n",
        "    loss=keras.losses.CategoricalCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uQVhFV9jbmHs"
      },
      "outputs": [],
      "source": [
        "#追加学習の場合 - 1/1\n",
        "model = keras.models.load_model(rundir + 'my_model.h5') #ファイル名は適宜．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHXriYh5IRjI",
        "outputId": "6e74b497-cc75-4923-a33d-60575b041588"
      },
      "outputs": [],
      "source": [
        "#学習\n",
        "#RAMに載せる\n",
        "epochs = 10\n",
        "#batch_size=32なのは，アップロードしているデータが50件程度しかないため．実際の学習の際は64にしていた．\n",
        "history = model.fit([x_train, c_18_train, r_18_train], y_train, batch_size=32, epochs=epochs, verbose=1, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rJT_7M3FK1ta"
      },
      "outputs": [],
      "source": [
        "model.save(rundir + 'my_model_2.h5') #ファイル名は適宜．"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
